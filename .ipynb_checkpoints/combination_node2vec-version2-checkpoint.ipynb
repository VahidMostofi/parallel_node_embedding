{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = './data/astroph/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_COUNT = 4\n",
    "\n",
    "if BATCH_COUNT == 4:\n",
    "    set_of_combinations = [(0,1),(1,2),(2,3)]\n",
    "elif BATCH_COUNT == 8:\n",
    "    set_of_combinations = [(0,1), (1,2), (2,3), (3,4), (4,5), (5,6), (6,7), \n",
    "                (0,3), (3,6), (1,4), (2,5), (4,7), \n",
    "                (0,2),(1,3), (2,4), (3,5), (4,6), (5,7),\n",
    "                (0,4),(1,5),(2,6),(3,7)]\n",
    "\n",
    "# node2vec settings\n",
    "WINDOW_SIZE = 10 # Context size for optimization\n",
    "NUM_WALKS = 10 # Number of walks per source\n",
    "WALK_LENGTH = 80 # Length of walk per source\n",
    "DIMENSIONS = 128 # Embedding dimension\n",
    "DIRECTED = False # Graph directed/undirected\n",
    "WORKERS = 6 # Num. parallel workers\n",
    "ITER = 1 # SGD epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_embeddings(emb_mappings, edge_list):\n",
    "    embs = []\n",
    "    for edge in edge_list:\n",
    "        node1 = edge[0]\n",
    "        node2 = edge[1]\n",
    "        if node1 in emb_mappings:\n",
    "            emb1 = emb_mappings[node1]\n",
    "        else:\n",
    "            continue\n",
    "        if node2 in emb_mappings:\n",
    "            emb2 = emb_mappings[node2]\n",
    "        else:\n",
    "            continue\n",
    "        edge_emb = np.multiply(emb1, emb2)\n",
    "        embs.append(edge_emb)\n",
    "    embs = np.array(embs)\n",
    "    return embs\n",
    "\n",
    "\n",
    "def read_edge_list(file_path):\n",
    "    with open(file_path) as f:\n",
    "        tmp = [(line.split(' ')[0],line.split(' ')[1]) for line in f.read().split('\\n')[:-1]]\n",
    "        tmp = [(str(min(int(a[0]),int(a[1]))),str(max(int(a[0]),int(a[1])))) for a in tmp]\n",
    "        return tmp\n",
    "        \n",
    "\n",
    "def get_combination_model(first, second, verbose=True):\n",
    "    edge_list_path = working_dir + str(first)+'_'+str(second)+'_edges.txt'\n",
    "    first_nodes_path = working_dir + str(first) + '_nodes.txt'\n",
    "    second_nodes_path = working_dir + str(second) + '_nodes.txt'\n",
    "\n",
    "    first_node2vec = {}\n",
    "    second_node2vec = {}\n",
    "    edge_list = []\n",
    "\n",
    "    with open(edge_list_path) as f:\n",
    "        edge_list = [line.split(' ') for line in f.read().split('\\n')[:-1]]\n",
    "    edge_list =[(str(min(int(edge[0]), int(edge[1]))), str(max(int(edge[0]), int(edge[1])))) for edge in edge_list]\n",
    "    for e in edge_list:\n",
    "        assert int(e[0]) <= int(e[1])\n",
    "\n",
    "    with open(first_nodes_path) as f:\n",
    "        for node in f.read().split('\\n'):\n",
    "            if node.strip() != '':\n",
    "                first_node2vec[node.strip()] = None\n",
    "\n",
    "    with open(second_nodes_path) as f:\n",
    "        for node in f.read().split('\\n'):\n",
    "            if node.strip() != '':\n",
    "                second_node2vec[node.strip()] = None\n",
    "\n",
    "    all_nodes = list(first_node2vec.keys()) + list(second_node2vec.keys())\n",
    "    g_train = nx.read_edgelist(edge_list_path)\n",
    "    start_time = time.time()\n",
    "    node2vec = Node2Vec(g_train, dimensions=DIMENSIONS, walk_length=WALK_LENGTH, num_walks=NUM_WALKS, workers=WORKERS)\n",
    "    model = node2vec.fit(window=WINDOW_SIZE, min_count=0, iter=ITER, workers=WORKERS)\n",
    "    print('node2vec took', time.time() - start_time)\n",
    "    emb_mappings = model.wv\n",
    "    #     print('len(emb_mappings)', len(emb_mappings))\n",
    "\n",
    "    train_edges_false = []\n",
    "    for e in read_edge_list(working_dir + 'train_edges_false.txt'):\n",
    "        assert int(e[0]) <= int(e[1])\n",
    "        if e[0] in emb_mappings and e[1] in emb_mappings:\n",
    "            train_edges_false.append(e)\n",
    "\n",
    "    while(len(train_edges_false) < len(edge_list)):\n",
    "        idx_i = int(all_nodes[np.random.randint(0, len(all_nodes))])\n",
    "        idx_j = int(all_nodes[np.random.randint(0, len(all_nodes))])\n",
    "\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "\n",
    "        false_edge = (str(min(idx_i, idx_j)), str(max(idx_i, idx_j)))\n",
    "        idx_i = false_edge[0]\n",
    "        idx_j = false_edge[1]\n",
    "        if idx_i not in emb_mappings:\n",
    "            continue\n",
    "        if idx_j not in emb_mappings:\n",
    "            continue\n",
    "        # Make sure false_edge not an actual edge, and not a repeat\n",
    "        if false_edge in train_edges_false:\n",
    "            continue\n",
    "        if false_edge in edge_list:\n",
    "            continue\n",
    "\n",
    "        train_edges_false.append(false_edge)\n",
    "\n",
    "    for e in train_edges_false:\n",
    "        assert int(e[0]) <= int(e[1])\n",
    "\n",
    "    edge_list_set = set(edge_list)\n",
    "    train_edges_false_set = set(train_edges_false)\n",
    "    print(len(edge_list_set.intersection(train_edges_false_set))) #todo make assert\n",
    "\n",
    "    pos_train_edge_embs = get_edge_embeddings(emb_mappings, edge_list)\n",
    "    neg_train_edge_embs = get_edge_embeddings(emb_mappings, train_edges_false)\n",
    "\n",
    "    train_edge_embs = np.concatenate([pos_train_edge_embs, neg_train_edge_embs])\n",
    "\n",
    "    # Create train-set edge labels: 1 = real edge, 0 = false edge\n",
    "    train_edge_labels = np.concatenate([\n",
    "        np.ones(pos_train_edge_embs.shape[0]), np.zeros(neg_train_edge_embs.shape[0])\n",
    "    ])\n",
    "\n",
    "    assert pos_train_edge_embs.shape[0] == neg_train_edge_embs.shape[0]\n",
    "\n",
    "    # if verbose:\n",
    "    #     print(pos_train_edge_embs.shape, neg_train_edge_embs.shape, train_edge_labels.shape)\n",
    "\n",
    "    edge_classifier = LogisticRegression(random_state=0, solver='lbfgs', max_iter=250)\n",
    "    edge_classifier.fit(train_edge_embs, train_edge_labels)\n",
    "\n",
    "    for key in first_node2vec.keys():\n",
    "        if key in emb_mappings:\n",
    "            first_node2vec[key] = emb_mappings[key]\n",
    "        else:\n",
    "            first_node2vec[key] = np.zeros((128,))\n",
    "\n",
    "    for key in second_node2vec.keys():\n",
    "        if key in emb_mappings:\n",
    "            second_node2vec[key] = emb_mappings[key]\n",
    "        else:\n",
    "            second_node2vec[key] = np.zeros((128,))\n",
    "    \n",
    "    emb_mappings = {}\n",
    "    for key in first_node2vec.keys():\n",
    "        emb_mappings[key] = first_node2vec[key]\n",
    "    for key in second_node2vec.keys():\n",
    "        emb_mappings[key] = second_node2vec[key]\n",
    "    return {\n",
    "        'model': edge_classifier,\n",
    "        'first_node2vec': first_node2vec,\n",
    "        'second_node2vec': second_node2vec,\n",
    "        'emb_mappings': emb_mappings\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 8375/8375 [00:15<00:00, 526.93it/s] \n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:52<00:00, 52.11s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:51<00:00, 51.75s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [01:29<00:00, 44.97s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [01:30<00:00, 45.17s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [01:30<00:00, 45.11s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [01:29<00:00, 45.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node2vec took 120.31948709487915\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 8437/8437 [00:16<00:00, 514.91it/s] \n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:44<00:00, 44.39s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:44<00:00, 44.04s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [01:20<00:00, 40.25s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [01:20<00:00, 40.06s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [01:19<00:00, 39.78s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [01:18<00:00, 39.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node2vec took 110.74743604660034\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 8384/8384 [00:15<00:00, 525.40it/s] \n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:50<00:00, 50.68s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:48<00:00, 48.83s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [01:29<00:00, 44.51s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [01:29<00:00, 44.53s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [01:28<00:00, 44.34s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [01:26<00:00, 43.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node2vec took 118.85155606269836\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "parts_graph = nx.Graph()\n",
    "combinations = {}\n",
    "\n",
    "for comb in set_of_combinations:\n",
    "    combinations[comb] = {}    \n",
    "    parts_graph.add_edge(*comb)\n",
    "    \n",
    "for comb in set_of_combinations:\n",
    "    combinations[comb] = get_combination_model(*comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_nodes = []\n",
    "for batch_idx in range(BATCH_COUNT):\n",
    "    batch_nodes.append([])\n",
    "    \n",
    "for key, value in combinations.items():\n",
    "    batch_nodes[key[0]] = list(value['first_node2vec'].keys())\n",
    "    batch_nodes[key[1]] = list(value['second_node2vec'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_edge_true = read_edge_list(working_dir + 'test_edges_true.txt')\n",
    "test_edge_false= read_edge_list(working_dir + 'test_edges_false.txt')\n",
    "test_edges = []\n",
    "\n",
    "for e in test_edge_true:\n",
    "    test_edges.append((e[0],e[1],1))\n",
    "    \n",
    "for e in test_edge_false:\n",
    "    test_edges.append((e[0],e[1],0))\n",
    "\n",
    "ignored_edges  = read_edge_list(working_dir + 'ignored_edges.txt')\n",
    "ignored_edges = [(e[0],e[1],1) for e in ignored_edges] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances0 + distances1 + distances2 =  len(test_edges)\n",
      "74153 + 29294 + 14771 = 118218\n",
      "118218 = 118218\n"
     ]
    }
   ],
   "source": [
    "def get_batch_idx(node, verbose=False):\n",
    "    for batch_idx in range(BATCH_COUNT):\n",
    "        if node in batch_nodes[batch_idx]:\n",
    "            if verbose:\n",
    "                print(node,'is in', batch_idx)\n",
    "            return batch_idx\n",
    "    assert False\n",
    "    \n",
    "def get_combination(b1,b2=None):\n",
    "    if b2 == None:\n",
    "        for comb in combinations.keys():\n",
    "            if b1 in comb:\n",
    "                return comb\n",
    "    else:\n",
    "        for comb in combinations.keys():\n",
    "            if (b1,b2) == comb:\n",
    "                return comb\n",
    "    \n",
    "distances0 = 0\n",
    "distances1 = 0\n",
    "distances2 = 0\n",
    "for e in test_edges:\n",
    "    batch_x = get_batch_idx(e[0])\n",
    "    batch_y = get_batch_idx(e[1])\n",
    "    distance = len(nx.shortest_path(parts_graph, batch_x, batch_y))\n",
    "    if distance == 2 or distance == 1:\n",
    "        distances0 += 1\n",
    "    elif distance == 3:\n",
    "        distances1 += 1\n",
    "    elif distance == 4:\n",
    "        distances2 += 1\n",
    "    else:\n",
    "        print(distance, nx.shortest_path(parts_graph, batch_x, batch_y))\n",
    "    \n",
    "print('distances0 + distances1 + distances2 = ', 'len(test_edges)')\n",
    "print(distances0,'+',distances1,'+',distances2,'=',len(test_edges))\n",
    "print(distances0 + distances1 + distances2, '=', len(test_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_in_other_half(values, node):\n",
    "    lookforin = None\n",
    "    node_vector = values['emb_mappings'][node]\n",
    "    \n",
    "    if node in values['first_node2vec']:\n",
    "        lookforin = values['second_node2vec']\n",
    "    elif node in values['second_node2vec']:\n",
    "        lookforin = values['first_node2vec']\n",
    "    \n",
    "    node_name = None\n",
    "    distance = 10000\n",
    "    for other_node, other_vector in lookforin.items():\n",
    "        dis =  np.linalg.norm(other_vector - node_vector)\n",
    "        if dis < distance:\n",
    "            distance = dis\n",
    "            node_name = other_node\n",
    "    return node_name, values['emb_mappings'][node_name]\n",
    "\n",
    "def get_prediction(node1, node2):\n",
    "\n",
    "    batch_x = min(get_batch_idx(node1), get_batch_idx(node2))\n",
    "    batch_y = max(get_batch_idx(node1), get_batch_idx(node2))\n",
    "\n",
    "    path = nx.shortest_path(parts_graph, batch_x, batch_y)\n",
    "    \n",
    "    if len(path) == 1 or len(path) == 2:\n",
    "        if len(path) == 1:\n",
    "            comb_name = get_combination(path[0])\n",
    "        elif len(path) == 2:\n",
    "            comb_name = get_combination(path[0], path[1])\n",
    "\n",
    "        values = combinations[comb_name]\n",
    "        edge_emb = np.multiply(\n",
    "            values['emb_mappings'][node1], \n",
    "            values['emb_mappings'][node2]\n",
    "        )\n",
    "        pred = values['model'].predict_proba([edge_emb])[:, 1]\n",
    "        return pred\n",
    "    \n",
    "    elif len(path) == 3:\n",
    "        alpha = None\n",
    "        theta = None\n",
    "        if node1 in batch_nodes[path[0]]:\n",
    "            alpha = node1\n",
    "            theta = node2\n",
    "        elif node1 in batch_nodes[path[2]]:\n",
    "            alpha = node2\n",
    "            theta = node1\n",
    "\n",
    "        alpha_embeding = combinations[(path[0],path[1])]['emb_mappings'][alpha]\n",
    "        theta_embeding = combinations[(path[1],path[2])]['emb_mappings'][theta]\n",
    "        \n",
    "        #alpha_prim = the most similar one to alpha in path[1] & (path[0],path[1])\n",
    "        alpha_prime, alpha_prime_vec = get_similar_in_other_half(combinations[(path[0],path[1])], alpha)\n",
    "        alpha_prime_in_12_vec = combinations[(path[1],path[2])]['emb_mappings'][alpha_prime]\n",
    "\n",
    "        #theta_prim = the most similar one to theta in path[1] & (path[1],path[2]) #todo I can use this too\n",
    "\n",
    "        comb_name = (path[1],path[2])\n",
    "        values = combinations[comb_name]\n",
    "        edge_emb = np.multiply(\n",
    "            alpha_prime_in_12_vec, \n",
    "            theta_embeding #theta is already in 12\n",
    "        )\n",
    "        pred = values['model'].predict_proba([edge_emb])[:, 1]\n",
    "        return pred\n",
    "    \n",
    "    elif len(path) == 4:\n",
    "        if node1 in batch_nodes[path[0]]:\n",
    "            alpha = node1\n",
    "            theta = node2\n",
    "        elif node1 in batch_nodes[path[3]]:\n",
    "            alpha = node2\n",
    "            theta = node1\n",
    "        \n",
    "        alpha_embeding = combinations[(path[0],path[1])]['emb_mappings'][alpha]\n",
    "        theta_embeding = combinations[(path[2],path[3])]['emb_mappings'][theta]\n",
    "\n",
    "    #     alpha_prim = the most similar one to alpha in path[1] & (path[0],path[1])\n",
    "        alpha_prime, alpha_prime_vec = get_similar_in_other_half(combinations[(path[0],path[1])], alpha)\n",
    "        alpha_prime_in_12_vec = combinations[(path[1],path[2])]['emb_mappings'][alpha_prime]\n",
    "\n",
    "    #     theta_prim = the most similar one to theta in path[2] & (path[2],path[3])\n",
    "        theta_prim, theta_prim_vec = get_similar_in_other_half(combinations[(path[2],path[3])], theta)\n",
    "        theta_prime_in_12_vec = combinations[(path[1],path[2])]['emb_mappings'][theta_prim]\n",
    "\n",
    "        comb_name = (path[1],path[2])\n",
    "        values = combinations[comb_name]\n",
    "        edge_emb = np.multiply(\n",
    "            alpha_prime_in_12_vec, \n",
    "            theta_prime_in_12_vec\n",
    "        )\n",
    "        pred = values['model'].predict_proba([edge_emb])[:, 1]\n",
    "        return pred\n",
    "    else:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 101318/118218 [20:38<04:46, 59.06it/s] "
     ]
    }
   ],
   "source": [
    "test_edge_lbls = []\n",
    "test_edge_pred = []\n",
    "\n",
    "for e in tqdm(test_edges):\n",
    "    pred = get_prediction(e[0],e[1])\n",
    "    test_edge_pred.append(pred)\n",
    "    test_edge_lbls.append(e[2])\n",
    "\n",
    "test_roc = roc_auc_score(test_edge_lbls, test_edge_pred)\n",
    "test_ap = average_precision_score(test_edge_lbls, test_edge_pred)\n",
    "\n",
    "\n",
    "print(len(test_edge_lbls),'out of', len(test_edges))\n",
    "print ('node2vec Test ROC score: ', str(test_roc))\n",
    "print ('node2vec Test AP score: ', str(test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edge_lbls = []\n",
    "test_edge_pred = []\n",
    "\n",
    "for e in tqdm(ignored_edges):\n",
    "    pred = get_prediction(e[0],e[1])\n",
    "    test_edge_pred.append(pred)\n",
    "    test_edge_lbls.append(e[2])\n",
    "\n",
    "print('ignored edges: (best value is 1.0)')\n",
    "print ('acc: ', np.array(test_edge_pred).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(test_edge_pred)\n",
    "preds[preds > 0.5].shape[0] / preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
