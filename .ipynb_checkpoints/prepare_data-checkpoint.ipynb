{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './data/ca-AstroPh.txt'\n",
    "working_dir = './data/astroph/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FRACTION = .3\n",
    "BATCH_COUNT = 4\n",
    "if BATCH_COUNT == 8:\n",
    "    COMBINATIONS = [(0,1), (1,2), (2,3), (3,4), (4,5), (5,6), (6,7), \n",
    "                (0,3), (3,6), (1,4), (2,5), (4,7), \n",
    "                (0,2),(1,3), (2,4), (3,5), (4,6), (5,7),\n",
    "                (0,4),(1,5),(2,6),(3,7)]\n",
    "if BATCH_COUNT == 4:\n",
    "    COMBINATIONS = [(0,1),(1,2),(2,3),(0,3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. choose the largest connected component of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17903 197031 lcc\n"
     ]
    }
   ],
   "source": [
    "if working_dir[-1] != '/':\n",
    "    working_dir += '/'\n",
    "\n",
    "graph = nx.read_edgelist(input_path)\n",
    "graphs = list(nx.connected_component_subgraphs(graph))\n",
    "graph = max(graphs, key=len)\n",
    "print(len(graph.nodes),len(graph.edges), 'lcc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. relabel the graph's nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_label_mapping = {}\n",
    "\n",
    "new_labels = list(range(len(graph.nodes())))\n",
    "\n",
    "random.Random(4).shuffle(new_labels)\n",
    "\n",
    "for node_idx, node_name in enumerate(graph.nodes()):\n",
    "    node_label_mapping[node_name] = str(new_labels[node_idx])\n",
    "\n",
    "graph = nx.relabel_nodes(graph, node_label_mapping)\n",
    "\n",
    "edge_list = list(graph.edges)[:]\n",
    "edge_list =[(min(int(edge[0]), int(edge[1])), max(int(edge[0]), int(edge[1]))) for edge in edge_list]\n",
    "\n",
    "with open(working_dir + 'all_edges.txt','w+') as f:\n",
    "    for edge in edge_list:\n",
    "        f.write(str(edge[0]) + ' ' + str(edge[1]) + '\\n')\n",
    "        \n",
    "assert max([int(a) for a in graph.nodes()]) == len(graph.nodes()) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. make train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_count 59109\n",
      "edge_list 197031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a7bfc4865d4d7a94556d4555cab70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=197031), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5000 removed_edges 4969\n",
      "step 10000 removed_edges 9943\n",
      "step 15000 removed_edges 14914\n",
      "step 20000 removed_edges 19884\n",
      "step 25000 removed_edges 24850\n",
      "step 30000 removed_edges 29821\n",
      "step 35000 removed_edges 34780\n",
      "step 40000 removed_edges 39731\n",
      "step 45000 removed_edges 44678\n",
      "step 50000 removed_edges 49635\n",
      "step 55000 removed_edges 54574\n",
      "train_edges_true, test_edges_true extracted\n",
      "test_edges_false extracted\n",
      "train_edges_false extracted\n"
     ]
    }
   ],
   "source": [
    "def make_train_test(graph, test_frac=.1, prevent_disconnect=True, verbose=True):\n",
    "    nodes = list(graph.nodes())\n",
    "    \n",
    "    removed_edges = []\n",
    "    edge_list = list(graph.edges)[:]\n",
    "    edge_list =[(str(min(int(edge[0]), int(edge[1]))), str(max(int(edge[0]), int(edge[1])))) for edge in edge_list]\n",
    "\n",
    "    random.Random(4).shuffle(edge_list)\n",
    "    \n",
    "    test_count = int(test_frac * len(edge_list))\n",
    "    print('test_count', test_count)\n",
    "    print('edge_list', len(edge_list))\n",
    "    step = 0\n",
    "    for edge in tqdm_notebook(edge_list):\n",
    "        step += 1\n",
    "        graph.remove_edge(edge[0], edge[1])\n",
    "        if nx.is_connected(graph) == False:\n",
    "            graph.add_edge(edge[0], edge[1])\n",
    "        else:\n",
    "            removed_edges.append(edge)\n",
    "        \n",
    "        if step % 5000 == 0:\n",
    "            print('step',step,'removed_edges',len(removed_edges))\n",
    "        if len(removed_edges) == test_count:\n",
    "            break\n",
    "\n",
    "    test_edges_true = removed_edges[:]\n",
    "    train_edges_true = list(graph.edges())\n",
    "    train_edges_true = [(str(min(int(edge[0]), int(edge[1]))), str(max(int(edge[0]), int(edge[1])))) for edge in train_edges_true]\n",
    "    print('train_edges_true, test_edges_true extracted')\n",
    "    \n",
    "    edge_list_dict = {}\n",
    "    for e in edge_list:\n",
    "        if e[0] not in edge_list_dict:\n",
    "            edge_list_dict[e[0]] = []\n",
    "        edge_list_dict[e[0]].append(e[1])\n",
    "    \n",
    "\n",
    "    test_edges_false = set()\n",
    "    while(len(test_edges_false) < test_count):\n",
    "        idx_i = int(nodes[np.random.randint(0, len(graph.nodes()))])\n",
    "        idx_j = int(nodes[np.random.randint(0, len(graph.nodes()))])\n",
    "\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "\n",
    "        false_edge = (str(min(idx_i, idx_j)), str(max(idx_i, idx_j)))\n",
    "        idx_i = false_edge[0]\n",
    "        idx_j = false_edge[1]\n",
    "        # Make sure false_edge not an actual edge, and not a repeat\n",
    "        if idx_i in edge_list_dict:\n",
    "            if idx_j in edge_list_dict[idx_i]:\n",
    "                continue\n",
    "        if false_edge in test_edges_false:\n",
    "            continue\n",
    "\n",
    "        test_edges_false.add(false_edge)\n",
    "    print('test_edges_false extracted')\n",
    "\n",
    "    train_edges_false = set()\n",
    "    while(len(train_edges_false) < len(train_edges_true)):\n",
    "        idx_i = int(nodes[np.random.randint(0, len(graph.nodes()))])\n",
    "        idx_j = int(nodes[np.random.randint(0, len(graph.nodes()))])\n",
    "\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "\n",
    "        false_edge = (str(min(idx_i, idx_j)), str(max(idx_i, idx_j)))\n",
    "        idx_i = false_edge[0]\n",
    "        idx_j = false_edge[1]\n",
    "        # Make sure false_edge not an actual edge, and not a repeat\n",
    "        if idx_i in edge_list_dict:\n",
    "            if idx_j in edge_list_dict[idx_i]:\n",
    "                continue\n",
    "        if false_edge in train_edges_false:\n",
    "            continue\n",
    "        if false_edge in test_edges_false:\n",
    "            continue\n",
    "\n",
    "        train_edges_false.add(false_edge)\n",
    "    print('train_edges_false extracted')\n",
    "    \n",
    "    ####### performe some test ########\n",
    "    for ss_idx, ss in enumerate([\n",
    "        train_edges_true,\n",
    "        train_edges_false,\n",
    "        test_edges_true,\n",
    "        test_edges_false]):\n",
    "        for e in ss:\n",
    "            if int(e[0]) > int(e[1]):\n",
    "                print('problem at', ss_idx)\n",
    "                assert False\n",
    "    \n",
    "    train_edges_true_set = set(train_edges_true)\n",
    "    train_edges_false_set = set(train_edges_false)\n",
    "    test_edges_true_set = set(test_edges_true)\n",
    "    test_edges_false_set = set(test_edges_false)\n",
    "    assert len(train_edges_true_set.intersection(train_edges_false_set)) == 0\n",
    "    assert len(train_edges_true_set.intersection(test_edges_true_set)) == 0\n",
    "    assert len(train_edges_true_set.intersection(test_edges_false_set)) == 0\n",
    "\n",
    "    assert len(train_edges_false_set.intersection(test_edges_true_set)) == 0\n",
    "    assert len(train_edges_false_set.intersection(test_edges_false_set)) == 0\n",
    "\n",
    "    assert len(test_edges_true_set.intersection(test_edges_false_set)) == 0\n",
    "\n",
    "    return train_edges_true, train_edges_false, test_edges_true, test_edges_false\n",
    "    \n",
    "train_edges_true, train_edges_false, test_edges_true, test_edges_false = make_train_test(graph, test_frac=TEST_FRACTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_edge_list(edge_list, filename):\n",
    "    with open(filename, 'w+') as f:\n",
    "        for e in edge_list:\n",
    "            f.write(str(e[0]) + ' ' + str(e[1]) + '\\n')\n",
    "    print(filename, 'created')\n",
    "    \n",
    "def read_edge_list(file_path):\n",
    "    with open(file_path) as f:\n",
    "        return [(line.split(' ')[0],line.split(' ')[1]) for line in f.read().split('\\n')[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_edges_true),len(train_edges_false),len(test_edges_true),len(test_edges_false)\n",
      "137922 137922 59109 59109\n",
      "./data/astroph/train_edges_true.txt created\n",
      "./data/astroph/train_edges_false.txt created\n",
      "./data/astroph/test_edges_true.txt created\n",
      "./data/astroph/test_edges_false.txt created\n"
     ]
    }
   ],
   "source": [
    "print('len(train_edges_true),len(train_edges_false),len(test_edges_true),len(test_edges_false)')\n",
    "print(len(train_edges_true),len(train_edges_false),len(test_edges_true),len(test_edges_false))\n",
    "\n",
    "write_edge_list(train_edges_true, working_dir + 'train_edges_true.txt')\n",
    "write_edge_list(train_edges_false, working_dir + 'train_edges_false.txt')\n",
    "write_edge_list(test_edges_true, working_dir + 'test_edges_true.txt')\n",
    "write_edge_list(test_edges_false, working_dir + 'test_edges_false.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137922\n",
      "137922\n",
      "59109\n",
      "59109\n"
     ]
    }
   ],
   "source": [
    "train_edges_true  = read_edge_list(working_dir + 'train_edges_true.txt')\n",
    "train_edges_false = read_edge_list(working_dir + 'train_edges_false.txt')\n",
    "test_edges_true   = read_edge_list(working_dir + 'test_edges_true.txt')\n",
    "test_edges_false  = read_edge_list(working_dir + 'test_edges_false.txt')\n",
    "print(len(train_edges_true))\n",
    "print(len(train_edges_false))\n",
    "print(len(test_edges_true))\n",
    "print(len(test_edges_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 combinations\n"
     ]
    }
   ],
   "source": [
    "print(len(COMBINATIONS),'combinations')\n",
    "BATCH_SIZE = int(len(graph.nodes()) / BATCH_COUNT) + 1\n",
    "\n",
    "parts_graph = nx.Graph()\n",
    "combination_edges = []\n",
    "for comb in COMBINATIONS:\n",
    "    parts_graph.add_edge(comb[0],comb[1])\n",
    "    combination_edges.append([])\n",
    "\n",
    "assert nx.diameter(parts_graph) <= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197031/197031 [00:00<00:00, 203279.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73194 edgs ignored 0.37148469022641106\n",
      "./data/astroph/ignored_edges.txt created\n",
      "./data/astroph/0_1_edges.txt created\n",
      "./data/astroph/1_2_edges.txt created\n",
      "./data/astroph/2_3_edges.txt created\n",
      "./data/astroph/0_nodes.txt created\n",
      "./data/astroph/1_nodes.txt created\n",
      "./data/astroph/2_nodes.txt created\n",
      "./data/astroph/3_nodes.txt created\n"
     ]
    }
   ],
   "source": [
    "input_path = working_dir + 'all_edges.txt'\n",
    "graph = nx.read_edgelist(input_path)\n",
    "    \n",
    "def is_in(A1, A2, n1, n2):\n",
    "    n1 = int(n1)\n",
    "    n2 = int(n2)\n",
    "    if(n1 in A1 and n2 in A2):\n",
    "        return True\n",
    "    if(n1 in A2 and n2 in A1):\n",
    "        return True\n",
    "    if(n1 in A1 and n2 in A1):\n",
    "        return True\n",
    "    if(n2 in A2 and n1 in A2):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "batch_ranges = []\n",
    "for i in range(BATCH_COUNT):\n",
    "    batch_ranges.append(range(i * BATCH_SIZE, (i+1) * BATCH_SIZE))\n",
    "\n",
    "batch_nodes = []\n",
    "for _ in range(BATCH_COUNT):\n",
    "    batch_nodes.append([])\n",
    "for node in graph.nodes():\n",
    "    for batch_idx in range(BATCH_COUNT):\n",
    "        if int(node) in batch_ranges[batch_idx]:\n",
    "            batch_nodes[batch_idx].append(node)\n",
    "\n",
    "ignored_edges = []\n",
    "for e in tqdm(list(graph.edges())):\n",
    "    ignored = True\n",
    "    for comb_idx, comb in enumerate(COMBINATIONS):\n",
    "        if(is_in(batch_ranges[comb[0]], batch_ranges[comb[1]], e[0], e[1])):\n",
    "            combination_edges[comb_idx].append((e[0],e[1]))\n",
    "            ignored = False\n",
    "    if ignored:\n",
    "        ignored_edges.append((e[0],e[1]))\n",
    "\n",
    "print(len(ignored_edges),'edgs ignored', len(ignored_edges) / (len(train_edges_true) + len(test_edges_true)))\n",
    "\n",
    "write_edge_list(ignored_edges, working_dir+'ignored_edges.txt')\n",
    "\n",
    "for comb_idx, comb in enumerate(COMBINATIONS):\n",
    "    write_edge_list(combination_edges[comb_idx], working_dir + str(comb[0]) + '_' + str(comb[1]) + '_edges.txt')\n",
    "\n",
    "for batch_idx in range(BATCH_COUNT):\n",
    "    f_name = working_dir + str(batch_idx) + '_nodes.txt'\n",
    "    with open(f_name, 'w+') as f:\n",
    "        for node in batch_nodes[batch_idx]:\n",
    "            f.write(str(node) + '\\n')\n",
    "    print(f_name,'created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_nodes[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
