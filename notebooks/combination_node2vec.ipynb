{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './data/facebook/'\n",
    "BATCH_COUNT = 8\n",
    "# node2vec settings\n",
    "WINDOW_SIZE = 10 # Context size for optimization\n",
    "NUM_WALKS = 10 # Number of walks per source\n",
    "WALK_LENGTH = 80 # Length of walk per source\n",
    "DIMENSIONS = 128 # Embedding dimension\n",
    "DIRECTED = False # Graph directed/undirected\n",
    "WORKERS = 6 # Num. parallel workers\n",
    "ITER = 1 # SGD epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_embeddings(emb_mappings, edge_list):\n",
    "    embs = []\n",
    "    for edge in edge_list:\n",
    "        node1 = edge[0]\n",
    "        node2 = edge[1]\n",
    "        if node1 in emb_mappings:\n",
    "            emb1 = emb_mappings[node1]\n",
    "        else:\n",
    "            continue\n",
    "        if node2 in emb_mappings:\n",
    "            emb2 = emb_mappings[node2]\n",
    "        else:\n",
    "            continue\n",
    "        edge_emb = np.multiply(emb1, emb2)\n",
    "        embs.append(edge_emb)\n",
    "    embs = np.array(embs)\n",
    "    return embs\n",
    "\n",
    "\n",
    "def read_edge_list(file_path):\n",
    "    with open(file_path) as f:\n",
    "        return [(line.split(' ')[0],line.split(' ')[1]) for line in f.read().split('\\n')[:-1]]\n",
    "        \n",
    "\n",
    "def get_combination_model(first, second, verbose=True):\n",
    "    edge_list_path = input_dir + str(first)+'_'+str(second)+'_edges.txt'\n",
    "    first_nodes_path = input_dir + str(first) + '_nodes.txt'\n",
    "    second_nodes_path = input_dir + str(second) + '_nodes.txt'\n",
    "\n",
    "    first_node2vec = {}\n",
    "    second_node2vec = {}\n",
    "    edge_list = []\n",
    "\n",
    "    with open(edge_list_path) as f:\n",
    "        edge_list = [line.split(' ') for line in f.read().split('\\n')[:-1]]\n",
    "    edge_list =[(str(min(int(edge[0]), int(edge[1]))), str(max(int(edge[0]), int(edge[1])))) for edge in edge_list]\n",
    "    for e in edge_list:\n",
    "        assert int(e[0]) <= int(e[1])\n",
    "\n",
    "    with open(first_nodes_path) as f:\n",
    "        for node in f.read().split('\\n'):\n",
    "            if node.strip() != '':\n",
    "                first_node2vec[node.strip()] = None\n",
    "\n",
    "    with open(second_nodes_path) as f:\n",
    "        for node in f.read().split('\\n'):\n",
    "            if node.strip() != '':\n",
    "                second_node2vec[node.strip()] = None\n",
    "\n",
    "    all_nodes = list(first_node2vec.keys()) + list(second_node2vec.keys())\n",
    "    g_train = nx.read_edgelist(edge_list_path)\n",
    "    start_time = time.time()\n",
    "    node2vec = Node2Vec(g_train, dimensions=DIMENSIONS, walk_length=WALK_LENGTH, num_walks=NUM_WALKS, workers=WORKERS)\n",
    "    model = node2vec.fit(window=WINDOW_SIZE, min_count=0, iter=ITER, workers=WORKERS)\n",
    "    print('node2vec took', time.time() - start_time)\n",
    "    emb_mappings = model.wv\n",
    "    #     print('len(emb_mappings)', len(emb_mappings))\n",
    "\n",
    "    train_edges_false = []\n",
    "    for e in read_edge_list(input_dir + 'train_edges_false.txt'):\n",
    "        assert int(e[0]) <= int(e[1])\n",
    "        if e[0] in emb_mappings and e[1] in emb_mappings:\n",
    "            train_edges_false.append(e)\n",
    "\n",
    "    while(len(train_edges_false) < len(edge_list)):\n",
    "        idx_i = int(all_nodes[np.random.randint(0, len(all_nodes))])\n",
    "        idx_j = int(all_nodes[np.random.randint(0, len(all_nodes))])\n",
    "\n",
    "        if idx_i == idx_j:\n",
    "            continue\n",
    "\n",
    "        false_edge = (str(min(idx_i, idx_j)), str(max(idx_i, idx_j)))\n",
    "        idx_i = false_edge[0]\n",
    "        idx_j = false_edge[1]\n",
    "        if idx_i not in emb_mappings:\n",
    "            continue\n",
    "        if idx_j not in emb_mappings:\n",
    "            continue\n",
    "        # Make sure false_edge not an actual edge, and not a repeat\n",
    "        if false_edge in train_edges_false:\n",
    "            continue\n",
    "        if false_edge in edge_list:\n",
    "            continue\n",
    "\n",
    "        train_edges_false.append(false_edge)\n",
    "\n",
    "    for e in train_edges_false:\n",
    "        assert int(e[0]) <= int(e[1])\n",
    "\n",
    "    edge_list_set = set(edge_list)\n",
    "    train_edges_false_set = set(train_edges_false)\n",
    "    assert len(edge_list_set.intersection(train_edges_false_set)) == 0\n",
    "\n",
    "    pos_train_edge_embs = get_edge_embeddings(emb_mappings, edge_list)\n",
    "    neg_train_edge_embs = get_edge_embeddings(emb_mappings, train_edges_false)\n",
    "\n",
    "    train_edge_embs = np.concatenate([pos_train_edge_embs, neg_train_edge_embs])\n",
    "\n",
    "    # Create train-set edge labels: 1 = real edge, 0 = false edge\n",
    "    train_edge_labels = np.concatenate([\n",
    "        np.ones(pos_train_edge_embs.shape[0]), np.zeros(neg_train_edge_embs.shape[0])\n",
    "    ])\n",
    "\n",
    "    assert pos_train_edge_embs.shape[0] == neg_train_edge_embs.shape[0]\n",
    "\n",
    "    # if verbose:\n",
    "    #     print(pos_train_edge_embs.shape, neg_train_edge_embs.shape, train_edge_labels.shape)\n",
    "\n",
    "    edge_classifier = LogisticRegression(random_state=0, solver='lbfgs', max_iter=250)\n",
    "    edge_classifier.fit(train_edge_embs, train_edge_labels)\n",
    "\n",
    "    for key in first_node2vec.keys():\n",
    "        if key in emb_mappings:\n",
    "            first_node2vec[key] = emb_mappings[key]\n",
    "        else:\n",
    "            first_node2vec[key] = np.zeros((128,))\n",
    "\n",
    "    for key in second_node2vec.keys():\n",
    "        if key in emb_mappings:\n",
    "            second_node2vec[key] = emb_mappings[key]\n",
    "        else:\n",
    "            second_node2vec[key] = np.zeros((128,))\n",
    "    \n",
    "    emb_mappings = {}\n",
    "    for key in first_node2vec.keys():\n",
    "        emb_mappings[key] = first_node2vec[key]\n",
    "    for key in second_node2vec.keys():\n",
    "        emb_mappings[key] = second_node2vec[key]\n",
    "    return {\n",
    "        'model': edge_classifier,\n",
    "        'first_node2vec': first_node2vec,\n",
    "        'second_node2vec': second_node2vec,\n",
    "        'emb_mappings': emb_mappings\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 1984/1984 [00:11<00:00, 169.68it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:08<00:00,  8.05s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:07<00:00,  7.99s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:14<00:00,  7.37s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:14<00:00,  7.39s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:14<00:00,  7.39s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:14<00:00,  7.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node2vec took 30.559221982955933\n"
     ]
    }
   ],
   "source": [
    "combinations[(0,1)] = get_combination_model(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 1974/1974 [00:09<00:00, 213.27it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:08<00:00,  8.14s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:08<00:00,  8.03s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:14<00:00,  7.29s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:14<00:00,  7.30s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:14<00:00,  7.35s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:14<00:00,  7.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node2vec took 27.757361888885498\n"
     ]
    }
   ],
   "source": [
    "combinations[(1,2)] = get_combination_model(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 1967/1967 [00:07<00:00, 253.11it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:08<00:00,  8.06s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:07<00:00,  7.98s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:14<00:00,  7.30s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:14<00:00,  7.32s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:14<00:00,  7.32s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:14<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node2vec took 26.147933959960938\n"
     ]
    }
   ],
   "source": [
    "combinations[(2,3)] = get_combination_model(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_nodes = []\n",
    "for batch_idx in range(BATCH_COUNT):\n",
    "    batch_nodes.append([])\n",
    "    \n",
    "for key, value in combinations.items():\n",
    "    batch_nodes[key[0]] = list(value['first_node2vec'].keys())\n",
    "    batch_nodes[key[1]] = list(value['second_node2vec'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_graph = nx.Graph()\n",
    "parts_graph.add_edge(0,1)\n",
    "parts_graph.add_edge(1,2)\n",
    "parts_graph.add_edge(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_edge_true = read_edge_list(input_dir + 'test_edges_true.txt')\n",
    "test_edge_false= read_edge_list(input_dir + 'test_edges_false.txt')\n",
    "test_edges = []\n",
    "for e in test_edge_true:\n",
    "    test_edges.append((e[0],e[1],1))\n",
    "for e in test_edge_false:\n",
    "    test_edges.append((e[0],e[1],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_idx(node):\n",
    "    for batch_idx in range(BATCH_COUNT):\n",
    "        if node in batch_nodes[batch_idx]:\n",
    "            return batch_idx\n",
    "    assert False\n",
    "    \n",
    "def get_combination(b1,b2=None):\n",
    "    if b2 == None:\n",
    "        for comb in combinations.keys():\n",
    "            if b1 in comb:\n",
    "                return comb\n",
    "    else:\n",
    "        for comb in combinations.keys():\n",
    "            if (b1,b2) == comb:\n",
    "                return comb\n",
    "    \n",
    "    \n",
    "distances0 = 0\n",
    "distances1 = 0\n",
    "distances2 = 0\n",
    "for e in test_edges:\n",
    "    batch_x = get_batch_idx(e[0])\n",
    "    batch_y = get_batch_idx(e[1])\n",
    "    distance = len(nx.shortest_path(parts_graph, batch_x, batch_y))\n",
    "    if distance == 2 or distance == 1:\n",
    "        distances0 += 1\n",
    "    elif distance == 3:\n",
    "        distances1 += 1\n",
    "    elif distance == 4:\n",
    "        distances2 += 1\n",
    "    else:\n",
    "        print(distance, nx.shortest_path(parts_graph, batch_x, batch_y))\n",
    "print(distances0 + distances1 + distances2, len(test_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_edge_embs = []\n",
    "test_edge_lbls = []\n",
    "test_edge_pred = []\n",
    "\n",
    "for e in tqdm(test_edges):\n",
    "    batch_x = min(get_batch_idx(e[0]),get_batch_idx(e[1]))\n",
    "    batch_y = max(get_batch_idx(e[0]),get_batch_idx(e[1]))\n",
    "    \n",
    "    path = nx.shortest_path(parts_graph, batch_x, batch_y)\n",
    "    \n",
    "    if len(path) == 1:\n",
    "        comb_name = get_combination(path[0])\n",
    "        values = combinations[comb_name]\n",
    "        edge_emb = np.multiply(\n",
    "            values['emb_mappings'][e[0]], \n",
    "            values['emb_mappings'][e[1]]\n",
    "        )\n",
    "        pred = values['model'].predict_proba([edge_emb])[:, 1]\n",
    "    elif len(path) == 2:\n",
    "        comb_name = get_combination(path[0], path[1])\n",
    "        values = combinations[comb_name]\n",
    "        edge_emb = np.multiply(\n",
    "            values['emb_mappings'][e[0]], \n",
    "            values['emb_mappings'][e[1]]\n",
    "        )\n",
    "        pred = values['model'].predict_proba([edge_emb])[:, 1]\n",
    "    if len(path) <= 2:    \n",
    "        test_edge_embs.append(edge_emb)\n",
    "        test_edge_lbls.append(e[2])\n",
    "        test_edge_pred.append(pred)\n",
    "    \n",
    "test_roc = roc_auc_score(test_edge_lbls, test_edge_pred)\n",
    "test_ap = average_precision_score(test_edge_lbls, test_edge_pred)\n",
    "print(len(test_edge_lbls),'out of', len(test_edges))\n",
    "print ('node2vec Test ROC score: ', str(test_roc))\n",
    "print ('node2vec Test AP score: ', str(test_ap))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_in_other_half(values, node):\n",
    "    lookforin = None\n",
    "    node_vector = values['emb_mappings'][node]\n",
    "    \n",
    "    if node in values['first_node2vec']:\n",
    "        lookforin = values['second_node2vec']\n",
    "    elif node in values['second_node2vec']:\n",
    "        lookforin = values['first_node2vec']\n",
    "    \n",
    "    node_name = None\n",
    "    distance = 10000\n",
    "    for other_node, other_vector in lookforin.items():\n",
    "        dis =  np.linalg.norm(other_vector - node_vector)\n",
    "        if dis < distance:\n",
    "            distance = dis\n",
    "            node_name = other_node\n",
    "    return node_name, values['emb_mappings'][node_name]\n",
    "    \n",
    "test_edge_embs = []\n",
    "test_edge_lbls = []\n",
    "test_edge_pred = []\n",
    "\n",
    "for e in tqdm(test_edges):\n",
    "    batch_x = min(get_batch_idx(e[0]),get_batch_idx(e[1]))\n",
    "    batch_y = max(get_batch_idx(e[0]),get_batch_idx(e[1]))\n",
    "    \n",
    "    path = nx.shortest_path(parts_graph, batch_x, batch_y)\n",
    "    \n",
    "    if len(path) != 3:\n",
    "        continue\n",
    "    if e[0] in batch_nodes[path[0]]:\n",
    "        alpha = e[0]\n",
    "        theta = e[1]\n",
    "        alpha_embeding = combinations[(path[0],path[1])]['emb_mappings'][alpha]\n",
    "        theta_embeding = combinations[(path[1],path[2])]['emb_mappings'][theta]\n",
    "    else:\n",
    "        alpha = e[1]\n",
    "        theta = e[0]\n",
    "        alpha_embeding = combinations[(path[1],path[2])]['emb_mappings'][alpha]\n",
    "        theta_embeding = combinations[(path[0],path[1])]['emb_mappings'][theta]\n",
    "        \n",
    "    \n",
    "#     alpha_prim = the most similar one to alpha in path[1] & (path[0],path[1])\n",
    "    alpha_prime, alpha_prime_vec = get_similar_in_other_half(combinations[(path[0],path[1])], alpha)\n",
    "    alpha_prime_in_B_vec = combinations[(path[1],path[2])]['emb_mappings'][alpha_prime]\n",
    "    \n",
    "#     theta_prim = the most similar one to theta in path[1] & (path[1],path[2])\n",
    "    theta_prim, theta_prim_vec = get_similar_in_other_half(combinations[(path[1],path[2])], theta)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     there would be 2 predictions: \n",
    "#         one using (path[0],path[1]) , (alpha, theta_prime)\n",
    "#         one using (path[1],path[2]) , (theta, alpha_prime)\n",
    "#     the average of these 2 is my opinion\n",
    "    \n",
    "#     if len(path) == 3:\n",
    "    comb_name = (path[1],path[2])\n",
    "    values = combinations[comb_name]\n",
    "    edge_emb = np.multiply(\n",
    "        alpha_prime_in_B_vec, \n",
    "        theta_embeding\n",
    "    )\n",
    "    pred = values['model'].predict_proba([edge_emb])[:, 1]\n",
    "\n",
    "    test_edge_embs.append(edge_emb)\n",
    "    test_edge_lbls.append(e[2])\n",
    "    test_edge_pred.append(pred)\n",
    "\n",
    "test_roc = roc_auc_score(test_edge_lbls, test_edge_pred)\n",
    "test_ap = average_precision_score(test_edge_lbls, test_edge_pred)\n",
    "\n",
    "print(len(test_edge_lbls),'out of', len(test_edges))\n",
    "print ('node2vec Test ROC score: ', str(test_roc))\n",
    "print ('node2vec Test AP score: ', str(test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_in_other_half(values, node):\n",
    "    lookforin = None\n",
    "    node_vector = values['emb_mappings'][node]\n",
    "    \n",
    "    if node in values['first_node2vec']:\n",
    "        lookforin = values['second_node2vec']\n",
    "    elif node in values['second_node2vec']:\n",
    "        lookforin = values['first_node2vec']\n",
    "    \n",
    "    node_name = None\n",
    "    distance = 10000\n",
    "    for other_node, other_vector in lookforin.items():\n",
    "        dis =  np.linalg.norm(other_vector - node_vector)\n",
    "        if dis < distance:\n",
    "            distance = dis\n",
    "            node_name = other_node\n",
    "    return node_name, values['emb_mappings'][node_name]\n",
    "    \n",
    "test_edge_embs = []\n",
    "test_edge_lbls = []\n",
    "test_edge_pred = []\n",
    "\n",
    "for e in tqdm(test_edges):\n",
    "    batch_x = min(get_batch_idx(e[0]),get_batch_idx(e[1]))\n",
    "    batch_y = max(get_batch_idx(e[0]),get_batch_idx(e[1]))\n",
    "    \n",
    "    path = nx.shortest_path(parts_graph, batch_x, batch_y)\n",
    "    \n",
    "    if len(path) != 4:\n",
    "        continue\n",
    "    if e[0] in batch_nodes[path[0]]:\n",
    "        alpha = e[0]\n",
    "        theta = e[1]\n",
    "        alpha_embeding = combinations[(path[0],path[1])]['emb_mappings'][alpha]\n",
    "        theta_embeding = combinations[(path[2],path[3])]['emb_mappings'][theta]\n",
    "    else:\n",
    "        alpha = e[1]\n",
    "        theta = e[0]\n",
    "        alpha_embeding = combinations[(path[2],path[3])]['emb_mappings'][alpha]\n",
    "        theta_embeding = combinations[(path[0],path[1])]['emb_mappings'][theta]\n",
    "    \n",
    "#     alpha_prim = the most similar one to alpha in path[1] & (path[0],path[1])\n",
    "    alpha_prime, alpha_prime_vec = get_similar_in_other_half(combinations[(path[0],path[1])], alpha)\n",
    "    alpha_prime_in_12_vec = combinations[(path[1],path[2])]['emb_mappings'][alpha_prime]\n",
    "    \n",
    "#     theta_prim = the most similar one to theta in path[2] & (path[2],path[3])\n",
    "    theta_prim, theta_prim_vec = get_similar_in_other_half(combinations[(path[2],path[3])], theta)\n",
    "    theta_prime_in_12_vec = combinations[(path[1],path[2])]['emb_mappings'][theta_prim]\n",
    "    \n",
    "    comb_name = (path[1],path[2])\n",
    "    values = combinations[comb_name]\n",
    "    edge_emb = np.multiply(\n",
    "        alpha_prime_in_12_vec, \n",
    "        theta_prime_in_12_vec\n",
    "    )\n",
    "    pred = values['model'].predict_proba([edge_emb])[:, 1]\n",
    "\n",
    "    test_edge_embs.append(edge_emb)\n",
    "    test_edge_lbls.append(e[2])\n",
    "    test_edge_pred.append(pred)\n",
    "\n",
    "test_roc = roc_auc_score(test_edge_lbls, test_edge_pred)\n",
    "test_ap = average_precision_score(test_edge_lbls, test_edge_pred)\n",
    "\n",
    "print(len(test_edge_lbls),'out of', len(test_edges))\n",
    "print ('node2vec Test ROC score: ', str(test_roc))\n",
    "print ('node2vec Test AP score: ', str(test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9751715475554089 * (13276/52940) + 0.9924898041533882 * (33033/52940) + 0.9704944447856797 * (6631/52940)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "33033 + 13276 + 6631"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
